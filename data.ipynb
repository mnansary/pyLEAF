{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "appointed-lexington",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "from coreLib.utils import *\n",
    "import numpy as np\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# data paths\n",
    "data_path=\"/media/ansary/DriveData/Work/LEAF/archive/\"\n",
    "train_path=os.path.join(data_path,'train')\n",
    "eval_path=os.path.join(data_path,'validation')\n",
    "# save paths\n",
    "save_path=\"/media/ansary/DriveData/Work/LEAF/\"\n",
    "save_path=create_dir(save_path,'data')\n",
    "train_save=create_dir(save_path,'train')\n",
    "test_save=create_dir(save_path,'test')\n",
    "\n",
    "# image aug\n",
    "ia.seed(1)\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5), # horizontal flips\n",
    "    iaa.Crop(percent=(0, 0.1)), # random crops\n",
    "    # Small gaussian blur with random sigma between 0 and 0.5.\n",
    "    # But we only blur about 50% of all images.\n",
    "    iaa.Sometimes(\n",
    "        0.5,\n",
    "        iaa.GaussianBlur(sigma=(0, 0.5))\n",
    "    ),\n",
    "    # Strengthen or weaken the contrast in each image.\n",
    "    iaa.LinearContrast((0.75, 1.5)),\n",
    "    # Add gaussian noise.\n",
    "    # For 50% of all images, we sample the noise once per pixel.\n",
    "    # For the other 50% of all images, we sample the noise per pixel AND\n",
    "    # channel. This can change the color (not only brightness) of the\n",
    "    # pixels.\n",
    "    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
    "    # Make some images brighter and some darker.\n",
    "    # In 20% of all cases, we sample the multiplier once per channel,\n",
    "    # which can end up changing the color of the images.\n",
    "    iaa.Multiply((0.8, 1.2), per_channel=0.2),\n",
    "    # Apply affine transformations to each image.\n",
    "    # Scale/zoom them, translate/move them, rotate them and shear them.\n",
    "    iaa.Affine(\n",
    "        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "        rotate=(-25, 25),\n",
    "        shear=(-8, 8)\n",
    "    )\n",
    "], random_order=True) # apply augmenters in random order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "lucky-christmas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd0d84f0b6d34ce2a17d93921323e4f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "data_dim=256\n",
    "n_aug=20\n",
    "train_paths=[_path for _path in glob(os.path.join(train_path,\"*/*.jpg\"))]\n",
    "for idx,img_path in tqdm(enumerate(train_paths),total=len(train_paths)):\n",
    "    img=cv2.imread(img_path)\n",
    "    img=cv2.resize(img,(data_dim,data_dim))\n",
    "    label=os.path.basename(os.path.dirname(img_path))\n",
    "    label_dir=create_dir(train_save,label)\n",
    "    cv2.imwrite(os.path.join(label_dir,f\"{idx}.png\"),img)\n",
    "    # aug\n",
    "    images=[img for _ in range(n_aug)]\n",
    "    images_aug = seq(images=images)\n",
    "    for iidx,img_aug in enumerate(images_aug):\n",
    "        cv2.imwrite(os.path.join(label_dir,f\"{idx}_{iidx}.png\"),img_aug)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "attempted-industry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd18a57b02f54e31ad0d91d13def415c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/492 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_paths=[_path for _path in glob(os.path.join(eval_path,\"*/*.jpg\"))]\n",
    "for idx,img_path in tqdm(enumerate(test_paths),total=len(test_paths)):\n",
    "    img=cv2.imread(img_path)\n",
    "    img=cv2.resize(img,(data_dim,data_dim))\n",
    "    label=os.path.basename(os.path.dirname(img_path))\n",
    "    label_dir=create_dir(test_save,label)\n",
    "    cv2.imwrite(os.path.join(label_dir,f\"{idx}.png\"),img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-reservoir",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leafenv",
   "language": "python",
   "name": "leafenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
